---
title: "Diamond Price Prediction using Multiple Linear Regression"
author: "Joon Soh"
date: "3/11/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Diamond Prediction

1. Load the data.

 - Import libraries that will be used for the project.
 
```{r}
library("tidyverse")
# library(plyr)
library(dplyr)
library(faraway) # for VIF
library(multcomp)
library(lawstat) # for levene's test
library(MASS) # qq plot
```

 - Set the directory to where the files are.

```{r}

# setwd("C:/Users/joony/Documents/myGit/STAT_6021_Project_1")

```

 - Load the data file. 
 
```{r}

data <- read.csv("clean_diamond_data.csv")

# if you want to use the columns without calling the table, attach the table
attach(data)

```

2. Examine the data

 - Display the first few rows of the table
 
```{r}

head(data)

```

 - Check if there is any missing values
 
```{r}

table(is.na(data))

```

 - Look at the count tables for categorical variables.
 
```{r}

table(data$color)

```

```{r}

table(data$clarity)

```

```{r}

table(data$cut)

```

 - Check the range for the numerical variables.
 
```{r}
 
range(data$carat)

```

```{r}

range(data$price)
 
```
Reorder color from worst class to best class.

```{r}
#reorder color from worst class to best class
data$color <- factor(data$color, levels=c("J","I","H","G","F","E","D"))

#reorder clarity from worst to best class
data$clarity <- factor(data$clarity, levels=c("SI2","SI1","VS2","VS1","VVS2","VVS1","IF", "FL"))

#reorder cut from worst to best class
data$cut <- factor(data$cut, levels=c("Good","Very Good","Ideal","Astor Ideal"))
 
```

3. Preliminary analysis

 - Plot boxplots and perform levene's test.


```{r}

boxplot(price~color,data=data, main="Price vs Color", xlab="Color", ylab="Price")

```

```{r}
# is variance of the response same for every categories?
# null is that variance is same 
levene.test(price,color)

```

 * Ascending order of the colors : "J","I","H","G","F","E","D"
 * Every color class has lots of outliers for high prices - the better the color, the more spread in the outliers.


```{r}

boxplot(price~clarity,data=data, main="Price vs Clarity", xlab="Clarity", ylab="Price ")

``` 

```{r}

levene.test(price,clarity)

```



 * Ascending order of the clarity : "SI2","SI1","VS2","VS1","VVS2","VVS1","IF", "FL"
 * Every clarity class has lots of outliers for high prices.
 
```{r}

boxplot(price~cut,data=data, main="Price vs Cut", xlab="Cut", ylab="Price")

```

```{r}

levene.test(price,cut)

```

 

 * Ascending order of the cuts : "Good","Very Good","Ideal","Astor Ideal"
 * Every cut class has lots of outliers for high prices - the better the cut, the more spread in the outliers.
 
 
 + The variances of the response for each categories are not same for different categories.
 + The ratio of the sizes of the largest and smallest categories are bigger than 1.5
 + Need to watch out for overestimating and underestimating of p-values.
 + Could consider using Welch Test instead.
 
 - Now, let's look a scatter plots of the data.
 
```{r}

title = "Price vs. Carat"
xlab = "Carat"
ylab ="Price"
x = carat
y = price

plot(x, y, main=title, xlab=xlab, ylab=ylab)

```
 - Check if there is a differential correlation.
 
```{r}

#let's plot carat vs price by colorscore
d1 <- subset(data, color=="J")
d2 <- subset(data, color=="I")
d3 <- subset(data, color=="H")
d4 <- subset(data, color=="G")
d5 <- subset(data, color=="F")
d6 <- subset(data, color=="E")
d7 <- subset(data, color=="D")
reg1 <- lm(price~carat, data=d1)
reg2 <- lm(price~carat, data=d2)
reg3 <- lm(price~carat, data=d3)
reg4 <- lm(price~carat, data=d4)
reg5 <- lm(price~carat, data=d5)
reg6 <- lm(price~carat, data=d6)
reg7 <- lm(price~carat, data=d7)
plot(carat, price, main="Price vs. Carat by Color", xlab=xlab, ylab=ylab)
points(d2$carat, d2$price, col='red')
points(d3$carat, d3$price, col='blue')
points(d4$carat, d4$price, col='green')
points(d5$carat, d5$price, col='pink')
points(d6$carat, d6$price, col='purple')
points(d7$carat, d7$price, col='orange')
abline(reg1, lty=1)
abline(reg2, lty=2, col='red')
abline(reg3, lty=3, col='blue')
abline(reg4, lty=4, col='green')
abline(reg5, lty=5, col='pink')
abline(reg6, lty=6, col='purple')
abline(reg7, lty=7, col='orange')
legend("topright", c("J","I","H","G","F","E","D"), lty=c(1,2,3,4,5,6,7), col=c('black','red','blue','green','pink','purple','orange'))


```
The slopes are not same for each categories. There still may be interaction.
 
```{r}

#let's plot carat vs price by clarityscore
d1 <- subset(data, clarity=="SI2")
d2 <- subset(data, clarity=="SI1")
d3 <- subset(data, clarity=="VS2")
d4 <- subset(data, clarity=="VS1")
d5 <- subset(data, clarity=="VVS2")
d6 <- subset(data, clarity=="VVS1")
d7 <- subset(data, clarity=="IF")
d8 <- subset(data, clarity=="FL")
reg1 <- lm(price~carat, data=d1)
reg2 <- lm(price~carat, data=d2)
reg3 <- lm(price~carat, data=d3)
reg4 <- lm(price~carat, data=d4)
reg5 <- lm(price~carat, data=d5)
reg6 <- lm(price~carat, data=d6)
reg7 <- lm(price~carat, data=d7)
reg8 <- lm(price~carat, data=d8)
plot(carat, price, main="Price vs. Carat by Clarity", xlab=xlab, ylab=ylab)
points(d2$carat, d2$price, col='red')
points(d3$carat, d3$price, col='blue')
points(d4$carat, d4$price, col='green')
points(d5$carat, d5$price, col='pink')
points(d6$carat, d6$price, col='purple')
points(d7$carat, d7$price, col='orange')
points(d8$carat, d8$price, col='brown')
abline(reg1, lty=1)
abline(reg2, lty=2, col='red')
abline(reg3, lty=3, col='blue')
abline(reg4, lty=4, col='green')
abline(reg5, lty=5, col='pink')
abline(reg6, lty=6, col='purple')
abline(reg7, lty=7, col='orange')
abline(reg8, lty=8, col='brown')
legend("topright", c("SI2","SI1","VS2","VS1","VVS2","VVS1","IF", "FL"), lty=c(1,2,3,4,5,6,7,8), col=c('black','red','blue','green','pink','purple','orange','brown'))


```

The slopes are not same for each categories. There still may be interaction.

```{r}

#let's plot carat vs price by cutscore
d1 <- subset(data, cut=="Good")
d2 <- subset(data, cut=="Very Good")
d3 <- subset(data, cut=="Ideal")
d4 <- subset(data, cut=="Astor Ideal")
reg1 <- lm(price~carat, data=d1)
reg2 <- lm(price~carat, data=d2)
reg3 <- lm(price~carat, data=d3)
reg4 <- lm(price~carat, data=d4)
plot(carat, price, main="Price vs. Carat by Cut", xlab=xlab, ylab=ylab)
points(d2$carat, d2$price, col='red')
points(d3$carat, d3$price, col='blue')
points(d4$carat, d4$price, col='green')
abline(reg1, lty=1)
abline(reg2, lty=2, col='red')
abline(reg3, lty=3, col='blue')
abline(reg4, lty=4, col='green')
legend("topright", c("Good","Very Good","Ideal","Astor Ideal"), lty=c(1,2,3,4), col=c('black','red','blue','green'))


```
The slopes are not same for each categories. There still may be interaction.

 4. Linear Regression Analysis

Now, Let's look at basic linear regression results. 

```{r}

lmodel <- lm(price~.,data)
summary(lmodel)

```

```{r}

##residual plot
plot(lmodel$fitted.values,lmodel$residuals,main="Residual Plot",xlab="Fitted Values", ylab="Residual Values")
abline(h=0,col="red")

```
The errors don't seem to have mean of 0 or equal variance. 

Let's look at ACF plot of residuals to check the independence of the error terms and check if there is correlation between the error terms.

```{r}

acf(lmodel$residuals, main="Autocorrelation Plot")

```
Blue lines represent the significant correlation threshold. It seems to have autocorrelation. 

Now let's check if ther normality assumtion is met through QQ plot. 

```{r}

## Normal probability or QQ plot of residuals
qqnorm(lmodel$residuals, main="Normal Probability Plot")
# add expected line based on the normality assumtion.
qqline(lmodel$residuals, col="red")

```

5. Transformations

```{r}
# boxcox plotting and transformation
boxcox(lmodel, lambda=seq(.37,0.375,by=0.001), main ="Box-cox plot")
```

```{r}
lamb <- 0.372


newPrice <- price^lamb

data_fixed <- data
data_fixed$price <- newPrice

attach(data_fixed)
```

```{r}

lmodel_fixed <- lm(price~.,data_fixed)
summary(lmodel_fixed)

```


```{r}

plot(lmodel_fixed$fitted.values,lmodel_fixed$residuals,main="Residual Plot",xlab="Fitted Values",ylab="Residual Values")
abline(h=0,col="red")
```

```{r}
##acf plot of residuals
acf(lmodel_fixed$residuals, main="Autocorrelation Plot")
```


```{r}
##QQ plot of residuals
qqnorm(lmodel_fixed$residuals, main="Normal Probability Plot")
qqline(lmodel_fixed$residuals, col="red")
```

Now that we transformed the response variable, we can transform the predictor variables. 

Let's look at the Carat variable. 

```{r}
title = "Price vs. Carat"
xlab = "Carat"
ylab ="Price"
x = carat
y = price

# Produce a plot. 
plot(x, y, main=title, xlab=xlab, ylab=ylab)

abline(lmodel_fixed, col="red")

plot(lmodel_fixed$fitted.values,lmodel_fixed$residuals,main="Residual Plot",xlab="Fitted Values",ylab="Residual Values")
abline(h=0,col="red")
```


```{r}
############ x ^ 1/2 section
lamb2 <- 1/2

newCaratSqrt <- carat^lamb2

datFormatted_fixed_sqrt <- data_fixed
datFormatted_fixed_sqrt$carat <- newCaratSqrt

lmodel_fixed_sqrt <- lm(price~.,datFormatted_fixed_sqrt)
summary(lmodel_fixed_sqrt)

title = "Price VS. Carat"
xlab = "Carat"
ylab ="Price"
x = datFormatted_fixed_sqrt$carat
y = datFormatted_fixed_sqrt$price

# Produce a plot. 
plot(x, y, main=title, xlab=xlab, ylab=ylab)

abline(lmodel_fixed_sqrt, col="red")
```

```{r}
##acf plot of residuals
acf(lmodel_fixed$residuals, main="Autocorrelation Plot")
```

```{r}
##QQ plot of residuals
qqnorm(lmodel_fixed$residuals, main="Normal Probability Plot")
qqline(lmodel_fixed$residuals, col="red")

```
Looks like a minor increase in the power can help with more precise fitting. 

```{r}
lamb2 <- .69

newCarat <- carat^lamb2

datFormatted_fixed2 <- data_fixed
datFormatted_fixed2$carat <- newCarat
attach(datFormatted_fixed2)

lmodel_fixed2 <- lm(price~.,datFormatted_fixed2)
summary(lmodel_fixed2)


title = "Price vs. Carat"
xlab = "Carat"
ylab ="Price"
x = carat
y = price

# Produce a plot. 
plot(x, y, main=title, xlab=xlab, ylab=ylab)

abline(lmodel_fixed2, col="red")

```

The predictor transformation is applied. 

```{r}

#let's plot carat vs price by colorscore
a1 <- subset(datFormatted_fixed2, color=="J")
a2 <- subset(datFormatted_fixed2, color=="I")
a3 <- subset(datFormatted_fixed2, color=="H")
a4 <- subset(datFormatted_fixed2, color=="G")
a5 <- subset(datFormatted_fixed2, color=="F")
a6 <- subset(datFormatted_fixed2, color=="E")
a7 <- subset(datFormatted_fixed2, color=="D")
reg1 <- lm(price~carat, data=a1)
reg2 <- lm(price~carat, data=a2)
reg3 <- lm(price~carat, data=a3)
reg4 <- lm(price~carat, data=a4)
reg5 <- lm(price~carat, data=a5)
reg6 <- lm(price~carat, data=a6)
reg7 <- lm(price~carat, data=a7)
plot(carat, price, main="Price vs. Carat by Color", xlab="Carat", ylab="Price")
points(a2$carat, a2$price, col='red')
points(a3$carat, a3$price, col='blue')
points(a4$carat, a4$price, col='green')
points(a5$carat, a5$price, col='pink')
points(a6$carat, a6$price, col='purple')
points(a7$carat, a7$price, col='orange')
abline(reg1, lty=1)
abline(reg2, lty=2, col='red')
abline(reg3, lty=3, col='blue')
abline(reg4, lty=4, col='green')
abline(reg5, lty=5, col='pink')
abline(reg6, lty=6, col='purple')
abline(reg7, lty=7, col='orange')
legend("topright", c("J","I","H","G","F","E","D"), lty=c(1,2,3,4,5,6,7), col=c('black','red','blue','green','pink','purple','orange'))
#the slopes for all of the lines are similar, but there still may be interaction


```

```{r}

#let's plot carat vs price by clarityscore
a1 <- subset(datFormatted_fixed2, clarity=="SI2")
a2 <- subset(datFormatted_fixed2, clarity=="SI1")
a3 <- subset(datFormatted_fixed2, clarity=="VS2")
a4 <- subset(datFormatted_fixed2, clarity=="VS1")
a5 <- subset(datFormatted_fixed2, clarity=="VVS2")
a6 <- subset(datFormatted_fixed2, clarity=="VVS1")
a7 <- subset(datFormatted_fixed2, clarity=="IF")
a8 <- subset(datFormatted_fixed2, clarity=="FL")
reg1 <- lm(price~carat, data=a1)
reg2 <- lm(price~carat, data=a2)
reg3 <- lm(price~carat, data=a3)
reg4 <- lm(price~carat, data=a4)
reg5 <- lm(price~carat, data=a5)
reg6 <- lm(price~carat, data=a6)
reg7 <- lm(price~carat, data=a7)
reg8 <- lm(price~carat, data=a8)
plot(carat, price, main="Price vs. Carat by Clarity", xlab="Carat", ylab="Price")
points(a2$carat, a2$price, col='red')
points(a3$carat, a3$price, col='blue')
points(a4$carat, a4$price, col='green')
points(a5$carat, a5$price, col='pink')
points(a6$carat, a6$price, col='purple')
points(a7$carat, a7$price, col='orange')
points(a8$carat, a8$price, col='yellow')
abline(reg1, lty=1)
abline(reg2, lty=2, col='red')
abline(reg3, lty=3, col='blue')
abline(reg4, lty=4, col='green')
abline(reg5, lty=5, col='pink')
abline(reg6, lty=6, col='purple')
abline(reg7, lty=7, col='orange')
abline(reg8, lty=8, col='yellow')
legend("topright", c("SI2","SI1","VS2","VS1","VVS2","VVS1","IF", "FL"), lty=c(1,2,3,4,5,6,7,8), col=c('black','red','blue','green','pink','purple','orange','yellow'))
#the slopes for all of the lines are similar, but there still may be interaction
```

```{r}

#let's plot carat vs price by cutscore
a1 <- subset(datFormatted_fixed2, cut=="Good")
a2 <- subset(datFormatted_fixed2, cut=="Very Good")
a3 <- subset(datFormatted_fixed2, cut=="Ideal")
a4 <- subset(datFormatted_fixed2, cut=="Astor Ideal")
reg1 <- lm(price~carat, data=a1)
reg2 <- lm(price~carat, data=a2)
reg3 <- lm(price~carat, data=a3)
reg4 <- lm(price~carat, data=a4)
plot(carat, price, main="Price vs. Carat by Cut", xlab="Carat", ylab="Price")
points(a2$carat, a2$price, col='red')
points(a3$carat, a3$price, col='blue')
points(a4$carat, a4$price, col='green')
abline(reg1, lty=1)
abline(reg2, lty=2, col='red')
abline(reg3, lty=3, col='blue')
abline(reg4, lty=4, col='green')
legend("topright", c("Good","Very Good","Ideal","Astor Ideal"), lty=c(1,2,3,4), col=c('black','red','blue','green'))
#the slopes for all of the lines are similar, but there still may be interaction

```

```{r}
##acf plot of residuals
acf(lmodel_fixed2$residuals,main="Autocorrelation Plot")

```

```{r}
##QQ plot of residuals
qqnorm(lmodel_fixed2$residuals, main="Normal Probability Plot")
qqline(lmodel_fixed2$residuals, col="red")

```

Both the response and numerical predictor are transformed now and the model is more compliant with the linear model assumptions.

Next, check for multicollinearity with VIF analysis. It will show by what factor the variance is multiplied by for this situation compared to a perfectly uncorrelated situation. 

VIF > 10 is commonly used to check for multicolinearity. 

```{r}
# perform vif analysis 
vif(lmodel_fixed2)
# none of the scores are over 10 ( all of them are actually less than 4)
```

None of the scores are over 10. 

6. Test statistics

Let's perform ANOVA test. 

```{r}

# perform anova test 
anova(lmodel_fixed2)

```

All of the predictors are considered significant.

Perform pairwise test to see if all categorical variables are significantly different in their means for price for each value.

```{r}
pairwise_clarity<-glht(lmodel_fixed2, linfct = mcp(clarity= "Tukey"))
summary(pairwise_clarity)
```

```{r}
pairwise_color<-glht(lmodel_fixed2, linfct = mcp(color= "Tukey"))
summary(pairwise_color)
```

```{r}
pairwise_cut<-glht(lmodel_fixed2, linfct = mcp(cut= "Tukey"))
summary(pairwise_cut)
```

They are all significantly different for all pairs.

Let's do partial F test for each categorical variable.

First, make the reduced linear regression model

```{r}
lmodel_noClarity <- lm(price~carat+color+cut)
lmodel_noColor <- lm(price~carat+clarity+cut)
lmodel_noCut <- lm(price~carat+clarity+color)
```

Perform the partial F test.

For clarity :

```{r}
anova(lmodel_noClarity, lmodel_fixed2)
```

For color :

```{r}
anova(lmodel_noColor, lmodel_fixed2)
```

For cut :

```{r}
anova(lmodel_noCut, lmodel_fixed2)
```

Partial F tests were significant for all of the categorical variables.

We can not drop any of the categorical variables.

Partial F tests on one interaction :

```{r}
lmodel_interactioncocl <- lm(price~carat+cut+clarity*color)
anova(lmodel_fixed2, lmodel_interactioncocl)
```

```{r}
summary(lmodel_interactioncocl)
```


```{r}
lmodel_interactioncocu <- lm(price~carat+clarity+cut*color)
anova(lmodel_fixed2, lmodel_interactioncocu)
```

```{r}
summary(lmodel_interactioncocu)
```


```{r}
lmodel_interactioncaco <- lm(price~clarity+cut+carat*color)
anova(lmodel_fixed2, lmodel_interactioncaco)
```

```{r}
summary(lmodel_interactioncaco)
```


```{r}
lmodel_interactionclcu <- lm(price~carat+color+clarity*cut)
anova(lmodel_fixed2, lmodel_interactionclcu)
```

```{r}
summary(lmodel_interactionclcu)
```


```{r}
lmodel_interactionclca <- lm(price~cut+color+clarity*carat)
anova(lmodel_fixed2, lmodel_interactionclca)
```

```{r}
summary(lmodel_interactionclca)
```



```{r}
lmodel_interactioncacu <- lm(price~clarity+color+carat*cut)
anova(lmodel_fixed2, lmodel_interactioncacu)
```

```{r}
summary(lmodel_interactioncacu)
```

All of the test results were significant. 


Partial f test on all interactions then between all and one.

```{r}
lmodel_fullInteraction <- lm(price~carat*clarity*cut*color)
summary(lmodel_fullInteraction)
```

```{r}
anova(lmodel_fixed2, lmodel_fullInteraction)
```

```{r}
anova(lmodel_fixed2, lmodel_interactioncaco)
```

```{r}
anova(lmodel_fixed2, lmodel_interactioncacu)
```

```{r}
anova(lmodel_fixed2, lmodel_interactionclca)
```

```{r}
anova(lmodel_fixed2, lmodel_interactionclcu)
```

```{r}
anova(lmodel_fixed2, lmodel_interactioncocl)
```

```{r}
anova(lmodel_fixed2, lmodel_interactioncocu)
```

All of the test results were significant. 

For easier interpretation, the model without interaction would work, but interaction terms would aid the prediction significantly.  
